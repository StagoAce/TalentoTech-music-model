{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QjiXcLqn2OJ"
   },
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIIbuF3fDY4i",
    "outputId": "81945ea6-2cbe-47e5-cace-583198424d22"
   },
   "outputs": [],
   "source": [
    "pip install librosa numpy pandas matplotlib tensorflow opencv-python scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iNaVJZ-YDU47"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "#import essentia.standard as es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Input, concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, concatenate, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC_2E3i4n5IJ"
   },
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yf-De381BNMH"
   },
   "outputs": [],
   "source": [
    "def extract_audio_features(file_path):\n",
    "    try:\n",
    "        # Cargar audio con librosa\n",
    "        y, sr = librosa.load(file_path, mono=True)\n",
    "        duration_ms = librosa.get_duration(y=y, sr=sr) * 1000  # Convertir a milisegundos\n",
    "\n",
    "        # Extraer características con librosa\n",
    "        features = {\n",
    "            \"duration_ms\": duration_ms,\n",
    "            \"tempo\": librosa.beat.tempo(y=y, sr=sr)[0],  # BPM\n",
    "            \"key\": np.argmax(librosa.feature.chroma_stft(y=y, sr=sr).mean(axis=1)),  # Aproximación de tonalidad\n",
    "            \"loudness\": np.mean(librosa.feature.rms(y=y)),  # Root Mean Square Energy\n",
    "            \"energy\": np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),  # Energía del espectro\n",
    "            \"danceability\": np.mean(librosa.feature.tempogram(y=y, sr=sr)),  # Relación con el ritmo\n",
    "            \"speechiness\": np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=1)),  # Proximidad a voz hablada\n",
    "            \"acousticness\": np.mean(librosa.feature.spectral_flatness(y=y)),  # Nivel de acústica\n",
    "            \"instrumentalness\": 1 - np.mean(librosa.feature.zero_crossing_rate(y=y)),  # Cantidad de transiciones en señal\n",
    "            \"liveness\": np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),  # Sensación de \"en vivo\"\n",
    "            \"valence\": np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),  # Percepción de alegría o tristeza\n",
    "        }\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)  # 13 coeficientes\n",
    "    return np.mean(mfccs, axis=1)  # Se obtiene la media de cada coeficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQQ-0Bz2ltgD"
   },
   "source": [
    "#Creamos y almacenamos imagenes del espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SClkx3dfOaT2",
    "outputId": "8235be8b-c23f-4a67-c676-6ffcd86e3af6"
   },
   "outputs": [],
   "source": [
    "# 📂 Carpetas de entrada y salida\n",
    "input_folders = {\n",
    "    \"Sobre\": \"/content/drive/MyDrive/canciones/Sobre\",\n",
    "    \"Debajo\": \"/content/drive/MyDrive/canciones/debajo\"\n",
    "}\n",
    "output_folder = \"/content/drive/MyDrive/canciones/Espectrogramas\"\n",
    "\n",
    "# 📌 Asegurar que la carpeta de salida existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 📌 Función para generar y guardar espectrogramas\n",
    "def generar_espectrograma(input_folder, label):\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp3\"):  # Filtrar solo archivos MP3\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            y, sr = librosa.load(file_path)  # Cargar audio\n",
    "\n",
    "            # 📌 Generar el espectrograma\n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "            # 📌 Crear la figura del espectrograma\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f\"Espectrograma - {file_name}\")\n",
    "\n",
    "            # 📌 Guardar la imagen con la categoría en el nombre\n",
    "            output_path = os.path.join(output_folder, f\"{label}_{file_name.replace('.mp3', '.png')}\")\n",
    "            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Guardado: {output_path}\")\n",
    "\n",
    "# 📌 Generar espectrogramas para ambas carpetas\n",
    "for label, folder in input_folders.items():\n",
    "    generar_espectrograma(folder, label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wocJFN0pnvhp"
   },
   "source": [
    "# Metricas de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Vnm9MB9aC5S",
    "outputId": "c46554c6-1c04-41c7-cd37-6ea40a50fa24"
   },
   "outputs": [],
   "source": [
    "# Specify the folder containing the audio files\n",
    "folder_path = \"/content/drive/MyDrive/canciones/debajo\"  # Replace with the actual folder path\n",
    "\n",
    "audio_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)\n",
    "               if file.endswith(('.mp3', '.wav', '.m4a'))]  # Add more extensions if needed\n",
    "\n",
    "# Process each file and store in a DataFrame\n",
    "data = []\n",
    "for file in audio_files:\n",
    "    features = extract_audio_features(file)\n",
    "    if features:\n",
    "        features[\"file_name\"] = file  # Agregar nombre del archivo\n",
    "        features[\"exito\"] = \"0\"  # You might need to adjust this based on your file organization\n",
    "\n",
    "        data.append(features)\n",
    "\n",
    "# Crear DataFrame con Pandas\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H7gJveIj0nJ",
    "outputId": "4ad3d6ea-7b51-41ff-aa1a-226b8a6e61f4"
   },
   "outputs": [],
   "source": [
    "# ... (extract_audio_features and extract_mfcc functions remain the same)\n",
    "\n",
    "# Specify the folder containing the audio files for data2\n",
    "folder_path2 = \"/content/drive/MyDrive/canciones/Sobre\"  # Replace with the actual folder path\n",
    "\n",
    "# Get a list of all files in the folder for data2\n",
    "audio_files2 = [os.path.join(folder_path2, file) for file in os.listdir(folder_path2)\n",
    "                if file.endswith(('.mp3', '.wav', '.m4a'))]  # Add more extensions if needed\n",
    "\n",
    "# Process each file and store in a DataFrame (data2)\n",
    "data2 = []\n",
    "for file in audio_files2:  # Use audio_files2 here\n",
    "    features = extract_audio_features(file)\n",
    "    if features:\n",
    "        features[\"file_name\"] = file  # Agregar nombre del archivo\n",
    "        features[\"exito\"] = \"1\"  # Change tipo to \"more1million\"\n",
    "\n",
    "        data2.append(features)\n",
    "\n",
    "# Crear DataFrame con Pandas (df2)\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hXCGNPxrDx_3",
    "outputId": "9fd1e381-1cc2-42a3-8787-27da55e531d4"
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['file_name']=df['file_name'].str.split('/content/drive/MyDrive/canciones/debajo/').str[-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "-0zJfkL-EKlW",
    "outputId": "cd381da7-4655-4600-f6a4-19f9d251b0d7"
   },
   "outputs": [],
   "source": [
    "df2.head()\n",
    "df2['file_name']=df2['file_name'].str.split('/content/drive/MyDrive/canciones/Sobre/').str[-1]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-UnJgldFzpz"
   },
   "outputs": [],
   "source": [
    "df_combinado = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "MIyrhJBJF-Fr",
    "outputId": "a0e4b6b8-6e6a-4709-8f73-f031b4cd2ea0"
   },
   "outputs": [],
   "source": [
    "df_combinado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4_GRHUrJkOL",
    "outputId": "c258b6db-934e-4d08-b2a1-9973ee9292a1"
   },
   "outputs": [],
   "source": [
    "# 📌 Guardar en Google Drive\n",
    "csv_filename = \"/content/drive/MyDrive/canciones/audio_features/audio_features.csv\"\n",
    "df_combinado.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado en: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSnSk3XypFcX"
   },
   "source": [
    "# MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "dir_path = r\"C:\\Users\\santi\\Documents\\cursos\\TalentoTech\\canciones\\Espectrogramas\"\n",
    "file_name = \"Debajo_Lenny Tavárez, Ryan Castro - Ojos Chinos (Official Visualizer).png\"\n",
    "\n",
    "# Función para normalizar el nombre del archivo (eliminar espacios y tildes)\n",
    "def normalize(name):\n",
    "    name = name.replace(\" \", \"\")  # Elimina espacios\n",
    "    name = unicodedata.normalize(\"NFKD\", name).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")  # Quita tildes\n",
    "    return name\n",
    "\n",
    "# Normalizar el nombre objetivo\n",
    "normalized_target = normalize(file_name)\n",
    "\n",
    "# Buscar en el directorio\n",
    "found = False\n",
    "for file in os.listdir(dir_path):\n",
    "    if normalize(file) == normalized_target:\n",
    "        print(f\"✅ Imagen encontrada: {file}\")\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(\"❌ Imagen NO encontrada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-QoQhItad0p",
    "outputId": "a0a3685b-e71d-4a62-92cc-3ef741d7ba4e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout,\n",
    "                                     BatchNormalization, GlobalAveragePooling2D, Concatenate)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Rutas de archivos\n",
    "CSV_PATH = r\"./audio_features.csv\"\n",
    "IMAGE_FOLDER = r\"./Espectrogramas/\"\n",
    "IMAGE_SIZE = (793, 373)\n",
    "\n",
    "# Función para normalizar el nombre del archivo (eliminar espacios y tildes)\n",
    "def normalize(name):\n",
    "    name = name.replace(\" \", \"\")  # Elimina espacios\n",
    "    name = unicodedata.normalize(\"NFKD\", name).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")  # Quita tildes\n",
    "    return name\n",
    "\n",
    "# Cargar y procesar datos\n",
    "def load_and_preprocess_data(csv_path, image_folder, image_size):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    features = ['duration_ms', 'tempo', 'key', 'loudness', 'energy', 'danceability', 'speechiness',\n",
    "                'acousticness', 'instrumentalness', 'liveness', 'valence']\n",
    "    y = df[\"exito\"].values\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    X_images, valid_file_names = [], []\n",
    "    for file_name in df[\"file_name\"]:\n",
    "        possible_names = [\n",
    "            f\"Sobre_{file_name.replace('.mp3', '.png')}\",\n",
    "            f\"Debajo_{file_name.replace('.mp3', '.png')}\"\n",
    "        ]\n",
    "        found_image = None\n",
    "        for img_file in os.listdir(image_folder):\n",
    "            if normalize(img_file) in [normalize(name) for name in possible_names]:\n",
    "                found_image = img_file\n",
    "                break\n",
    "        \n",
    "        if found_image:\n",
    "            image_path = os.path.join(image_folder, found_image)\n",
    "            try:\n",
    "                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, image_size)\n",
    "                X_images.append(img)\n",
    "                valid_file_names.append(file_name)\n",
    "            except Exception:\n",
    "                print(f\"⚠️ Error al cargar la imagen: {image_path}\")\n",
    "        else:\n",
    "            print(f\"⚠️ Imagen no encontrada para: {file_name}\")\n",
    "\n",
    "    if not X_images:\n",
    "        return None\n",
    "\n",
    "    X_images = np.array(X_images) / 255.0\n",
    "    X_images = X_images.reshape(-1, image_size[0], image_size[1], 1)\n",
    "    df_filtered = df[df[\"file_name\"].isin(valid_file_names)]\n",
    "    X_numeric = scaler.fit_transform(df_filtered[features].values)\n",
    "    y = df_filtered[\"exito\"].values\n",
    "    return X_numeric, X_images, y\n",
    "\n",
    "# Construcción del modelo\n",
    "def build_model(input_numeric_shape, image_size):\n",
    "    l2_reg = l2(0.001)\n",
    "\n",
    "    # Entrada de datos numéricos\n",
    "    input_numeric = Input(shape=(input_numeric_shape,))\n",
    "    redNProfunda = Dense(128, activation=\"relu\", kernel_regularizer=l2_reg)(input_numeric)\n",
    "    redNProfunda = BatchNormalization()(redNProfunda)\n",
    "    redNProfunda = Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(redNProfunda)\n",
    "\n",
    "    # Entrada de imagen (CNN)\n",
    "    input_image = Input(shape=(image_size[0], image_size[1], 1))\n",
    "    redNConvolucional = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(input_image)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    redNConvolucional = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(redNConvolucional)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    redNConvolucional = Conv2D(256, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(redNConvolucional)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    redNConvolucional = Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(redNConvolucional)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    # Aplanamos la salida de la CNN\n",
    "    flattened_redNConvolucional = Flatten()(redNConvolucional)\n",
    "\n",
    "    # Fusionamos la salida de la CNN con los datos numéricos\n",
    "    redNFusionada = Concatenate()([flattened_redNConvolucional, redNProfunda])\n",
    "\n",
    "    # Capas densas después de la fusión\n",
    "    redNFusionada = Dense(128, activation=\"relu\", kernel_regularizer=l2_reg)(redNFusionada)\n",
    "    redNFusionada = Dropout(0.5)(redNFusionada)\n",
    "    redNFusionada = Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(redNFusionada)\n",
    "    redNFusionada = Dropout(0.5)(redNFusionada)\n",
    "\n",
    "    # Capa de salida\n",
    "    output = Dense(1, activation=\"sigmoid\")(redNFusionada)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=[input_numeric, input_image], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "# Carga de datos\n",
    "data = load_and_preprocess_data(CSV_PATH, IMAGE_FOLDER, IMAGE_SIZE)\n",
    "if data:\n",
    "    X_numeric, X_images, y = data\n",
    "    X_train_num, X_test_num, X_train_img, X_test_img, y_train, y_test = train_test_split(\n",
    "        X_numeric, X_images, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    model = build_model(X_train_num.shape[1], IMAGE_SIZE)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=80, restore_best_weights=True)\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(\n",
    "        [X_train_num, X_train_img], y_train,\n",
    "        validation_data=([X_test_num, X_test_img], y_test),\n",
    "        epochs=150, batch_size=12, verbose=1,\n",
    "        callbacks=[early_stopping] #reduce_lr]\n",
    "    )\n",
    "\n",
    "    y_pred_prob = model.predict([X_test_num, X_test_img])\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # Evaluación con métricas adicionales\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "    print(f\"\\n🔍 F1-Score: {f1:.4f}\")\n",
    "    print(f\"🔍 AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Éxito\", \"Éxito\"], yticklabels=[\"No Éxito\", \"Éxito\"])\n",
    "    plt.xlabel(\"Predicción\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusión\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error en el procesamiento de datos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "0fof2zgVqKDu",
    "outputId": "28a2a598-3d6e-4069-ef78-425f32842114"
   },
   "outputs": [],
   "source": [
    "# Diagramar la pérdida\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Pérdida en Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='Pérdida en Validación')\n",
    "plt.title('Evolución de la Pérdida durante el Entrenamiento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfCrF47Q2lRc",
    "outputId": "a2f55f3e-bfcb-4111-d1e5-e45a452bdf64"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta donde se guardará el modelo\n",
    "MODEL_FOLDER = \"./modelo_guardado/\"\n",
    "MODEL_PATH = os.path.join(MODEL_FOLDER, \"modelo_prediccion_exito.h5\")\n",
    "\n",
    "# Eliminar la carpeta si ya existe\n",
    "if os.path.exists(MODEL_FOLDER):\n",
    "    shutil.rmtree(MODEL_FOLDER)\n",
    "\n",
    "# Crear la carpeta nuevamente\n",
    "os.makedirs(MODEL_FOLDER)\n",
    "\n",
    "# Guardar el modelo en la nueva carpeta\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "print(f\"✅ Modelo guardado en: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHxyjYkG2FXP"
   },
   "source": [
    "# Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IplsYWyG3acF",
    "outputId": "316e0a22-ebb5-4422-fee8-82f3e11bc8f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\santi\\AppData\\Local\\Temp\\ipykernel_13904\\3814532036.py:15: FutureWarning: librosa.beat.tempo\n",
      "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
      "\tThis alias will be removed in librosa version 1.0.\n",
      "  librosa.beat.tempo(y=y, sr=sr)[0],  # BPM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n",
      "[[0.]]\n",
      "Predicción para ./prueba/Grupo Frontera ft. Morat - LOS DOS (Visualizer).mp3: No éxito (0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "import librosa\n",
    "\n",
    "modelo = tf.keras.models.load_model(\"./modelo_entrenado_3/modelo_prediccion_exito.h5\")  # Asegúrate de guardar el modelo entrenado\n",
    "\n",
    "def extraer_caracteristicas_audio(archivo_mp3):\n",
    "    try:\n",
    "        # Cargar el audio con librosa\n",
    "        y, sr = librosa.load(archivo_mp3, mono=True)\n",
    "        duration_ms = librosa.get_duration(y=y, sr=sr) * 1000  # Convertir a milisegundos\n",
    "\n",
    "        # Extraer características\n",
    "        features = [\n",
    "            duration_ms,\n",
    "            librosa.beat.tempo(y=y, sr=sr)[0],  # BPM\n",
    "            np.argmax(librosa.feature.chroma_stft(y=y, sr=sr).mean(axis=1)),  # Aproximación de tonalidad\n",
    "            np.mean(librosa.feature.rms(y=y)),  # Root Mean Square Energy (volumen)\n",
    "            np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),  # Energía del espectro\n",
    "            np.mean(librosa.feature.tempogram(y=y, sr=sr)),  # Relación con el ritmo\n",
    "            np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=1)),  # Proximidad a voz hablada\n",
    "            np.mean(librosa.feature.spectral_flatness(y=y)),  # Nivel de acústica\n",
    "            1 - np.mean(librosa.feature.zero_crossing_rate(y=y)),  # Cantidad de transiciones en señal\n",
    "            np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),  # Sensación de \"en vivo\"\n",
    "            np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),  # Percepción de alegría o tristeza\n",
    "        ]\n",
    "\n",
    "        return np.array([features], dtype=np.float32)  # Forma correcta (1, 11)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {archivo_mp3}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generar_espectrograma(archivo_mp3):\n",
    "    \"\"\"Genera un espectrograma de la canción y lo redNConvolucionalierte a un array de imagen.\"\"\"\n",
    "    y, sr = librosa.load(archivo_mp3, sr=None)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Guardar el espectrograma temporalmente\n",
    "    ruta_espectrograma = \"temp_spec.png\"\n",
    "    plt.savefig(ruta_espectrograma, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    # Cargar el espectrograma como imagen y formatearlo\n",
    "    img = cv2.imread(ruta_espectrograma, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (373, 793))  # Ajusta el tamaño según el modelo\n",
    "    img = img / 255.0  # Normalización\n",
    "    return np.expand_dims(img, axis=0)  # Añadir dimensión batch\n",
    "\n",
    "def predecir_exito(archivo_mp3):\n",
    "    \"\"\"Realiza la predicción sobre un archivo MP3 dado.\"\"\"\n",
    "    # Extraer características numéricas\n",
    "    X_num = extraer_caracteristicas_audio(archivo_mp3)\n",
    "\n",
    "    # Generar espectrograma\n",
    "    X_img = generar_espectrograma(archivo_mp3)\n",
    "\n",
    "    # Hacer la predicción con el modelo\n",
    "    prediccion = modelo.predict([X_num, X_img])\n",
    "\n",
    "    # Interpretar la salida\n",
    "    resultado = \"Éxito\" if prediccion[0][0] > 0.5 else \"No éxito\"\n",
    "    print(prediccion)\n",
    "    print(f\"Predicción para {archivo_mp3}: {resultado} ({prediccion[0][0]:.4f})\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "archivo_prueba = \"./prueba/Grupo Frontera ft. Morat - LOS DOS (Visualizer).mp3\"  # Cambia esto por el archivo MP3 real\n",
    "predecir_exito(archivo_prueba)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9QjiXcLqn2OJ",
    "RC_2E3i4n5IJ",
    "xQQ-0Bz2ltgD",
    "wocJFN0pnvhp"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
