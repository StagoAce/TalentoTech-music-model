{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QjiXcLqn2OJ"
   },
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIIbuF3fDY4i",
    "outputId": "81945ea6-2cbe-47e5-cace-583198424d22"
   },
   "outputs": [],
   "source": [
    "pip install librosa numpy pandas matplotlib tensorflow opencv-python scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iNaVJZ-YDU47"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "#import essentia.standard as es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Input, concatenate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, concatenate, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC_2E3i4n5IJ"
   },
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yf-De381BNMH"
   },
   "outputs": [],
   "source": [
    "def extract_audio_features(file_path):\n",
    "    try:\n",
    "        # Cargar audio con librosa\n",
    "        y, sr = librosa.load(file_path, mono=True)\n",
    "        duration_ms = librosa.get_duration(y=y, sr=sr) * 1000  # Convertir a milisegundos\n",
    "\n",
    "        # Extraer caracter√≠sticas con librosa\n",
    "        features = {\n",
    "            \"duration_ms\": duration_ms,\n",
    "            \"tempo\": librosa.beat.tempo(y=y, sr=sr)[0],  # BPM\n",
    "            \"key\": np.argmax(librosa.feature.chroma_stft(y=y, sr=sr).mean(axis=1)),  # Aproximaci√≥n de tonalidad\n",
    "            \"loudness\": np.mean(librosa.feature.rms(y=y)),  # Root Mean Square Energy\n",
    "            \"energy\": np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),  # Energ√≠a del espectro\n",
    "            \"danceability\": np.mean(librosa.feature.tempogram(y=y, sr=sr)),  # Relaci√≥n con el ritmo\n",
    "            \"speechiness\": np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=1)),  # Proximidad a voz hablada\n",
    "            \"acousticness\": np.mean(librosa.feature.spectral_flatness(y=y)),  # Nivel de ac√∫stica\n",
    "            \"instrumentalness\": 1 - np.mean(librosa.feature.zero_crossing_rate(y=y)),  # Cantidad de transiciones en se√±al\n",
    "            \"liveness\": np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),  # Sensaci√≥n de \"en vivo\"\n",
    "            \"valence\": np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),  # Percepci√≥n de alegr√≠a o tristeza\n",
    "        }\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)  # 13 coeficientes\n",
    "    return np.mean(mfccs, axis=1)  # Se obtiene la media de cada coeficiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQQ-0Bz2ltgD"
   },
   "source": [
    "#Creamos y almacenamos imagenes del espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SClkx3dfOaT2",
    "outputId": "8235be8b-c23f-4a67-c676-6ffcd86e3af6"
   },
   "outputs": [],
   "source": [
    "# üìÇ Carpetas de entrada y salida\n",
    "input_folders = {\n",
    "    \"Sobre\": \"/content/drive/MyDrive/canciones/Sobre\",\n",
    "    \"Debajo\": \"/content/drive/MyDrive/canciones/debajo\"\n",
    "}\n",
    "output_folder = \"/content/drive/MyDrive/canciones/Espectrogramas\"\n",
    "\n",
    "# üìå Asegurar que la carpeta de salida existe\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# üìå Funci√≥n para generar y guardar espectrogramas\n",
    "def generar_espectrograma(input_folder, label):\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".mp3\"):  # Filtrar solo archivos MP3\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            y, sr = librosa.load(file_path)  # Cargar audio\n",
    "\n",
    "            # üìå Generar el espectrograma\n",
    "            S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "            # üìå Crear la figura del espectrograma\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='mel')\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f\"Espectrograma - {file_name}\")\n",
    "\n",
    "            # üìå Guardar la imagen con la categor√≠a en el nombre\n",
    "            output_path = os.path.join(output_folder, f\"{label}_{file_name.replace('.mp3', '.png')}\")\n",
    "            plt.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"Guardado: {output_path}\")\n",
    "\n",
    "# üìå Generar espectrogramas para ambas carpetas\n",
    "for label, folder in input_folders.items():\n",
    "    generar_espectrograma(folder, label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wocJFN0pnvhp"
   },
   "source": [
    "# Metricas de las canciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Vnm9MB9aC5S",
    "outputId": "c46554c6-1c04-41c7-cd37-6ea40a50fa24"
   },
   "outputs": [],
   "source": [
    "# Specify the folder containing the audio files\n",
    "folder_path = \"/content/drive/MyDrive/canciones/debajo\"  # Replace with the actual folder path\n",
    "\n",
    "audio_files = [os.path.join(folder_path, file) for file in os.listdir(folder_path)\n",
    "               if file.endswith(('.mp3', '.wav', '.m4a'))]  # Add more extensions if needed\n",
    "\n",
    "# Process each file and store in a DataFrame\n",
    "data = []\n",
    "for file in audio_files:\n",
    "    features = extract_audio_features(file)\n",
    "    if features:\n",
    "        features[\"file_name\"] = file  # Agregar nombre del archivo\n",
    "        features[\"exito\"] = \"0\"  # You might need to adjust this based on your file organization\n",
    "\n",
    "        data.append(features)\n",
    "\n",
    "# Crear DataFrame con Pandas\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-H7gJveIj0nJ",
    "outputId": "4ad3d6ea-7b51-41ff-aa1a-226b8a6e61f4"
   },
   "outputs": [],
   "source": [
    "# ... (extract_audio_features and extract_mfcc functions remain the same)\n",
    "\n",
    "# Specify the folder containing the audio files for data2\n",
    "folder_path2 = \"/content/drive/MyDrive/canciones/Sobre\"  # Replace with the actual folder path\n",
    "\n",
    "# Get a list of all files in the folder for data2\n",
    "audio_files2 = [os.path.join(folder_path2, file) for file in os.listdir(folder_path2)\n",
    "                if file.endswith(('.mp3', '.wav', '.m4a'))]  # Add more extensions if needed\n",
    "\n",
    "# Process each file and store in a DataFrame (data2)\n",
    "data2 = []\n",
    "for file in audio_files2:  # Use audio_files2 here\n",
    "    features = extract_audio_features(file)\n",
    "    if features:\n",
    "        features[\"file_name\"] = file  # Agregar nombre del archivo\n",
    "        features[\"exito\"] = \"1\"  # Change tipo to \"more1million\"\n",
    "\n",
    "        data2.append(features)\n",
    "\n",
    "# Crear DataFrame con Pandas (df2)\n",
    "df2 = pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hXCGNPxrDx_3",
    "outputId": "9fd1e381-1cc2-42a3-8787-27da55e531d4"
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "df['file_name']=df['file_name'].str.split('/content/drive/MyDrive/canciones/debajo/').str[-1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "-0zJfkL-EKlW",
    "outputId": "cd381da7-4655-4600-f6a4-19f9d251b0d7"
   },
   "outputs": [],
   "source": [
    "df2.head()\n",
    "df2['file_name']=df2['file_name'].str.split('/content/drive/MyDrive/canciones/Sobre/').str[-1]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-UnJgldFzpz"
   },
   "outputs": [],
   "source": [
    "df_combinado = pd.concat([df, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "MIyrhJBJF-Fr",
    "outputId": "a0e4b6b8-6e6a-4709-8f73-f031b4cd2ea0"
   },
   "outputs": [],
   "source": [
    "df_combinado.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4_GRHUrJkOL",
    "outputId": "c258b6db-934e-4d08-b2a1-9973ee9292a1"
   },
   "outputs": [],
   "source": [
    "# üìå Guardar en Google Drive\n",
    "csv_filename = \"/content/drive/MyDrive/canciones/audio_features/audio_features.csv\"\n",
    "df_combinado.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado en: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSnSk3XypFcX"
   },
   "source": [
    "# MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "dir_path = r\"C:\\Users\\santi\\Documents\\cursos\\TalentoTech\\canciones\\Espectrogramas\"\n",
    "file_name = \"Debajo_Lenny TavaÃÅrez, Ryan Castro - Ojos Chinos (Official Visualizer).png\"\n",
    "\n",
    "# Funci√≥n para normalizar el nombre del archivo (eliminar espacios y tildes)\n",
    "def normalize(name):\n",
    "    name = name.replace(\" \", \"\")  # Elimina espacios\n",
    "    name = unicodedata.normalize(\"NFKD\", name).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")  # Quita tildes\n",
    "    return name\n",
    "\n",
    "# Normalizar el nombre objetivo\n",
    "normalized_target = normalize(file_name)\n",
    "\n",
    "# Buscar en el directorio\n",
    "found = False\n",
    "for file in os.listdir(dir_path):\n",
    "    if normalize(file) == normalized_target:\n",
    "        print(f\"‚úÖ Imagen encontrada: {file}\")\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    print(\"‚ùå Imagen NO encontrada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-QoQhItad0p",
    "outputId": "a0a3685b-e71d-4a62-92cc-3ef741d7ba4e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout,\n",
    "                                     BatchNormalization, GlobalAveragePooling2D, Concatenate)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Rutas de archivos\n",
    "CSV_PATH = r\"./audio_features.csv\"\n",
    "IMAGE_FOLDER = r\"./Espectrogramas/\"\n",
    "IMAGE_SIZE = (793, 373)\n",
    "\n",
    "# Funci√≥n para normalizar el nombre del archivo (eliminar espacios y tildes)\n",
    "def normalize(name):\n",
    "    name = name.replace(\" \", \"\")  # Elimina espacios\n",
    "    name = unicodedata.normalize(\"NFKD\", name).encode(\"ASCII\", \"ignore\").decode(\"utf-8\")  # Quita tildes\n",
    "    return name\n",
    "\n",
    "# Cargar y procesar datos\n",
    "def load_and_preprocess_data(csv_path, image_folder, image_size):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    features = ['duration_ms', 'tempo', 'key', 'loudness', 'energy', 'danceability', 'speechiness',\n",
    "                'acousticness', 'instrumentalness', 'liveness', 'valence']\n",
    "    y = df[\"exito\"].values\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    X_images, valid_file_names = [], []\n",
    "    for file_name in df[\"file_name\"]:\n",
    "        possible_names = [\n",
    "            f\"Sobre_{file_name.replace('.mp3', '.png')}\",\n",
    "            f\"Debajo_{file_name.replace('.mp3', '.png')}\"\n",
    "        ]\n",
    "        found_image = None\n",
    "        for img_file in os.listdir(image_folder):\n",
    "            if normalize(img_file) in [normalize(name) for name in possible_names]:\n",
    "                found_image = img_file\n",
    "                break\n",
    "        \n",
    "        if found_image:\n",
    "            image_path = os.path.join(image_folder, found_image)\n",
    "            try:\n",
    "                img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, image_size)\n",
    "                X_images.append(img)\n",
    "                valid_file_names.append(file_name)\n",
    "            except Exception:\n",
    "                print(f\"‚ö†Ô∏è Error al cargar la imagen: {image_path}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Imagen no encontrada para: {file_name}\")\n",
    "\n",
    "    if not X_images:\n",
    "        return None\n",
    "\n",
    "    X_images = np.array(X_images) / 255.0\n",
    "    X_images = X_images.reshape(-1, image_size[0], image_size[1], 1)\n",
    "    df_filtered = df[df[\"file_name\"].isin(valid_file_names)]\n",
    "    X_numeric = scaler.fit_transform(df_filtered[features].values)\n",
    "    y = df_filtered[\"exito\"].values\n",
    "    return X_numeric, X_images, y\n",
    "\n",
    "# Construcci√≥n del modelo\n",
    "def build_model(input_numeric_shape, image_size):\n",
    "    l2_reg = l2(0.001)\n",
    "\n",
    "    # Entrada de datos num√©ricos\n",
    "    input_numeric = Input(shape=(input_numeric_shape,))\n",
    "    redNProfunda = Dense(128, activation=\"relu\", kernel_regularizer=l2_reg)(input_numeric)\n",
    "    redNProfunda = BatchNormalization()(redNProfunda)\n",
    "    redNProfunda = Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(redNProfunda)\n",
    "\n",
    "    # Entrada de imagen (CNN)\n",
    "    input_image = Input(shape=(image_size[0], image_size[1], 1))\n",
    "    redNConvolucional = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(input_image)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    redNConvolucional = Conv2D(128, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(redNConvolucional)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    redNConvolucional = Conv2D(256, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(redNConvolucional)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    redNConvolucional = Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg)(redNConvolucional)\n",
    "    redNConvolucional = BatchNormalization()(redNConvolucional)\n",
    "    redNConvolucional = MaxPooling2D(pool_size=(2,2))(redNConvolucional)\n",
    "\n",
    "    # Aplanamos la salida de la CNN\n",
    "    flattened_redNConvolucional = Flatten()(redNConvolucional)\n",
    "\n",
    "    # Fusionamos la salida de la CNN con los datos num√©ricos\n",
    "    redNFusionada = Concatenate()([flattened_redNConvolucional, redNProfunda])\n",
    "\n",
    "    # Capas densas despu√©s de la fusi√≥n\n",
    "    redNFusionada = Dense(128, activation=\"relu\", kernel_regularizer=l2_reg)(redNFusionada)\n",
    "    redNFusionada = Dropout(0.5)(redNFusionada)\n",
    "    redNFusionada = Dense(64, activation=\"relu\", kernel_regularizer=l2_reg)(redNFusionada)\n",
    "    redNFusionada = Dropout(0.5)(redNFusionada)\n",
    "\n",
    "    # Capa de salida\n",
    "    output = Dense(1, activation=\"sigmoid\")(redNFusionada)\n",
    "\n",
    "    # Definir el modelo\n",
    "    model = Model(inputs=[input_numeric, input_image], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001, clipnorm=1.0), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model\n",
    "# Carga de datos\n",
    "data = load_and_preprocess_data(CSV_PATH, IMAGE_FOLDER, IMAGE_SIZE)\n",
    "if data:\n",
    "    X_numeric, X_images, y = data\n",
    "    X_train_num, X_test_num, X_train_img, X_test_img, y_train, y_test = train_test_split(\n",
    "        X_numeric, X_images, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    model = build_model(X_train_num.shape[1], IMAGE_SIZE)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=80, restore_best_weights=True)\n",
    "    #reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "\n",
    "    history = model.fit(\n",
    "        [X_train_num, X_train_img], y_train,\n",
    "        validation_data=([X_test_num, X_test_img], y_test),\n",
    "        epochs=150, batch_size=12, verbose=1,\n",
    "        callbacks=[early_stopping] #reduce_lr]\n",
    "    )\n",
    "\n",
    "    y_pred_prob = model.predict([X_test_num, X_test_img])\n",
    "    y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "    # Evaluaci√≥n con m√©tricas adicionales\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "    print(f\"\\nüîç F1-Score: {f1:.4f}\")\n",
    "    print(f\"üîç AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No √âxito\", \"√âxito\"], yticklabels=[\"No √âxito\", \"√âxito\"])\n",
    "    plt.xlabel(\"Predicci√≥n\")\n",
    "    plt.ylabel(\"Real\")\n",
    "    plt.title(\"Matriz de Confusi√≥n\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Error en el procesamiento de datos.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566
    },
    "id": "0fof2zgVqKDu",
    "outputId": "28a2a598-3d6e-4069-ef78-425f32842114"
   },
   "outputs": [],
   "source": [
    "# Diagramar la p√©rdida\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='P√©rdida en Entrenamiento')\n",
    "plt.plot(history.history['val_loss'], label='P√©rdida en Validaci√≥n')\n",
    "plt.title('Evoluci√≥n de la P√©rdida durante el Entrenamiento')\n",
    "plt.xlabel('√âpocas')\n",
    "plt.ylabel('P√©rdida')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HfCrF47Q2lRc",
    "outputId": "a2f55f3e-bfcb-4111-d1e5-e45a452bdf64"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Ruta donde se guardar√° el modelo\n",
    "MODEL_FOLDER = \"./modelo_guardado/\"\n",
    "MODEL_PATH = os.path.join(MODEL_FOLDER, \"modelo_prediccion_exito.h5\")\n",
    "\n",
    "# Eliminar la carpeta si ya existe\n",
    "if os.path.exists(MODEL_FOLDER):\n",
    "    shutil.rmtree(MODEL_FOLDER)\n",
    "\n",
    "# Crear la carpeta nuevamente\n",
    "os.makedirs(MODEL_FOLDER)\n",
    "\n",
    "# Guardar el modelo en la nueva carpeta\n",
    "model.save(MODEL_PATH)\n",
    "\n",
    "print(f\"‚úÖ Modelo guardado en: {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHxyjYkG2FXP"
   },
   "source": [
    "# Prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IplsYWyG3acF",
    "outputId": "316e0a22-ebb5-4422-fee8-82f3e11bc8f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\santi\\AppData\\Local\\Temp\\ipykernel_13904\\3814532036.py:15: FutureWarning: librosa.beat.tempo\n",
      "\tThis function was moved to 'librosa.feature.rhythm.tempo' in librosa version 0.10.0.\n",
      "\tThis alias will be removed in librosa version 1.0.\n",
      "  librosa.beat.tempo(y=y, sr=sr)[0],  # BPM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520ms/step\n",
      "[[0.]]\n",
      "Predicci√≥n para ./prueba/Grupo Frontera ft. Morat - LOS DOS (Visualizer).mp3: No √©xito (0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado\n",
    "import librosa\n",
    "\n",
    "modelo = tf.keras.models.load_model(\"./modelo_entrenado_3/modelo_prediccion_exito.h5\")  # Aseg√∫rate de guardar el modelo entrenado\n",
    "\n",
    "def extraer_caracteristicas_audio(archivo_mp3):\n",
    "    try:\n",
    "        # Cargar el audio con librosa\n",
    "        y, sr = librosa.load(archivo_mp3, mono=True)\n",
    "        duration_ms = librosa.get_duration(y=y, sr=sr) * 1000  # Convertir a milisegundos\n",
    "\n",
    "        # Extraer caracter√≠sticas\n",
    "        features = [\n",
    "            duration_ms,\n",
    "            librosa.beat.tempo(y=y, sr=sr)[0],  # BPM\n",
    "            np.argmax(librosa.feature.chroma_stft(y=y, sr=sr).mean(axis=1)),  # Aproximaci√≥n de tonalidad\n",
    "            np.mean(librosa.feature.rms(y=y)),  # Root Mean Square Energy (volumen)\n",
    "            np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)),  # Energ√≠a del espectro\n",
    "            np.mean(librosa.feature.tempogram(y=y, sr=sr)),  # Relaci√≥n con el ritmo\n",
    "            np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=1)),  # Proximidad a voz hablada\n",
    "            np.mean(librosa.feature.spectral_flatness(y=y)),  # Nivel de ac√∫stica\n",
    "            1 - np.mean(librosa.feature.zero_crossing_rate(y=y)),  # Cantidad de transiciones en se√±al\n",
    "            np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)),  # Sensaci√≥n de \"en vivo\"\n",
    "            np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)),  # Percepci√≥n de alegr√≠a o tristeza\n",
    "        ]\n",
    "\n",
    "        return np.array([features], dtype=np.float32)  # Forma correcta (1, 11)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {archivo_mp3}: {e}\")\n",
    "        return None\n",
    "\n",
    "def generar_espectrograma(archivo_mp3):\n",
    "    \"\"\"Genera un espectrograma de la canci√≥n y lo redNConvolucionalierte a un array de imagen.\"\"\"\n",
    "    y, sr = librosa.load(archivo_mp3, sr=None)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Guardar el espectrograma temporalmente\n",
    "    ruta_espectrograma = \"temp_spec.png\"\n",
    "    plt.savefig(ruta_espectrograma, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    # Cargar el espectrograma como imagen y formatearlo\n",
    "    img = cv2.imread(ruta_espectrograma, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (373, 793))  # Ajusta el tama√±o seg√∫n el modelo\n",
    "    img = img / 255.0  # Normalizaci√≥n\n",
    "    return np.expand_dims(img, axis=0)  # A√±adir dimensi√≥n batch\n",
    "\n",
    "def predecir_exito(archivo_mp3):\n",
    "    \"\"\"Realiza la predicci√≥n sobre un archivo MP3 dado.\"\"\"\n",
    "    # Extraer caracter√≠sticas num√©ricas\n",
    "    X_num = extraer_caracteristicas_audio(archivo_mp3)\n",
    "\n",
    "    # Generar espectrograma\n",
    "    X_img = generar_espectrograma(archivo_mp3)\n",
    "\n",
    "    # Hacer la predicci√≥n con el modelo\n",
    "    prediccion = modelo.predict([X_num, X_img])\n",
    "\n",
    "    # Interpretar la salida\n",
    "    resultado = \"√âxito\" if prediccion[0][0] > 0.5 else \"No √©xito\"\n",
    "    print(prediccion)\n",
    "    print(f\"Predicci√≥n para {archivo_mp3}: {resultado} ({prediccion[0][0]:.4f})\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "archivo_prueba = \"./prueba/Grupo Frontera ft. Morat - LOS DOS (Visualizer).mp3\"  # Cambia esto por el archivo MP3 real\n",
    "predecir_exito(archivo_prueba)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9QjiXcLqn2OJ",
    "RC_2E3i4n5IJ",
    "xQQ-0Bz2ltgD",
    "wocJFN0pnvhp"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
